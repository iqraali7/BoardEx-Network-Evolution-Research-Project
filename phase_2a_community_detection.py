# -*- coding: utf-8 -*-
"""Phase 2a: Community Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gH-bKyn8-Lo0Us6iGxa8Mzgb738YTSD6
"""

!pip install datashader
!pip install datashader holoviews
import pandas as pd
import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import datashader as ds
import holoviews as hv
import community.community_louvain as community_louvain
import seaborn as sns
from holoviews.operation.datashader import bundle_graph
from collections import Counter
hv.extension('bokeh')

from google.colab import drive
drive.mount('/content/drive')

# Load the consolidated network
file_path = '/content/drive/My Drive/FinalSN1.csv'
network_data= pd.read_csv(file_path, encoding= 'latin', engine= 'python')

# Create a NetworkX graph from the edge list
G_combined = nx.from_pandas_edgelist(network_data, source='ISIN_x', target='ISIN_y', edge_attr='Weight')

# Filter network for k=3 (focus only on dense core)
G_core = nx.k_core(G_combined, k=3)  # Adjust k as needed

# Apply Louvain Community Detection
partition = community_louvain.best_partition(G_core,random_state=3)

# Add community information as node attributes
nx.set_node_attributes(G_core, partition, 'community')

# Convert NetworkX graph to HoloViews object with community as color
hv_graph = hv.Graph.from_networkx(G_core, nx.spring_layout).opts(
    node_color='community', cmap='Category20', colorbar=True, node_size=10)

# Apply edge bundling
bundled = bundle_graph(hv_graph)

# Plot the network with detected communities
hv.output(bundled.opts(width=800, height=800, edge_color='red'))

# Count the number of nodes in each community
community_counts = Counter(partition.values())

for community, count in community_counts.items():
    print(f"Community {community}: {count} nodes")

# Map the community information to the dataframe for both ISIN_x and ISIN_y
network_data['Community_ISIN_x'] = network_data['ISIN_x'].map(partition)
network_data['Community_ISIN_y'] = network_data['ISIN_y'].map(partition)

isin_x_data = network_data[['ISIN_x', 'Sector_x', 'Community_ISIN_x']].rename(columns={'ISIN_x': 'ISIN', 'Sector_x': 'Sector', 'Community_ISIN_x': 'Community'})
isin_y_data = network_data[['ISIN_y', 'Sector_y', 'Community_ISIN_y']].rename(columns={'ISIN_y': 'ISIN', 'Sector_y': 'Sector', 'Community_ISIN_y': 'Community'})

all_isin_data = pd.concat([isin_x_data, isin_y_data])

all_isin_data = all_isin_data.dropna(subset=['Community'])
all_isin_data = all_isin_data.drop_duplicates(subset=['ISIN'])

sector_counts = all_isin_data.groupby(['Community', 'Sector']).size().reset_index(name='Count')
total_nodes_by_community = all_isin_data.groupby('Community').size().reset_index(name='Total Nodes')
sector_proportions = pd.merge(sector_counts, total_nodes_by_community, on='Community')

# Function to group the remaining sectors 20% of sectors into 'Remaining Sectors'
def group_remaining_sectors(df, community_column='Community', sector_column='Sector', count_column='Count', threshold=0.8):
    result = []
    for community, group in df.groupby(community_column):
        group = group.sort_values(by=count_column, ascending=False)
        cumulative_sum = group[count_column].cumsum()
        total_count = group[count_column].sum()
        cutoff = total_count * threshold

        # Identify the sectors that together make up the top 80%
        top_sectors = group[cumulative_sum <= cutoff]
        remaining_sectors = group[cumulative_sum > cutoff]

        # If there are any remaining sectors, group them into a new category
        if not remaining_sectors.empty:
            remaining_sum = remaining_sectors[count_column].sum()
            result.append(pd.DataFrame({
                community_column: [community],
                sector_column: ['Remaining Sectors'],
                count_column: [remaining_sum],
                'Total Nodes': [total_count]
            }))

        result.append(top_sectors)

    return pd.concat(result)

# Group the remaining sectors into 'Remaining Sectors'
sector_proportions_grouped = group_remaining_sectors(sector_proportions)

sectors = sector_proportions_grouped['Sector'].unique()

unique_colors = sns.color_palette('husl', len(sectors))
color_dict = {sector: color for sector, color in zip(sectors, unique_colors)}

plt.figure(figsize=(12, 8))

pivot_table = sector_proportions_grouped.pivot_table(values='Count', index='Community', columns='Sector', aggfunc='sum', fill_value=0)
pivot_table.plot(kind='bar', stacked=True, figsize=(12, 8), color=[color_dict[col] for col in pivot_table.columns])

plt.xlabel('Community')
plt.ylabel('Number of Nodes')
plt.title('Board Interlock Network-Core Communities Makeup by Sector')
plt.legend(title='Sector', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()

plt.show()